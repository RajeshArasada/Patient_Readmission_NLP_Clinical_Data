{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Data Wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Saving\n",
    "import pickle\n",
    "\n",
    "# Feature Extraction and Feature Engineering\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc, classification_report, confusion_matrix\n",
    "\n",
    "# Model Interpretation\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          TEXT_CLEAN  Label\n",
      "0  admission date                discharge date  ...      0\n",
      "1  admission date                discharge date  ...      0\n",
      "2  admission date                discharge date  ...      0\n",
      "3  admission date                discharge date  ...      0\n",
      "4  admission date                discharge date  ...      0\n"
     ]
    }
   ],
   "source": [
    "# take a peek at the data\n",
    "df = pd.read_pickle('small_df.pickle')\n",
    "print(df.head())\n",
    "\n",
    "# shuffle the data and reset index\n",
    "data = df.sample(len(df))\n",
    "data = df.reset_index(drop=True)\n",
    "\n",
    "# build train, validation and test datasets \n",
    "data_valid_test = data.sample(frac=0.3)\n",
    "data_test = data_valid_test.sample(frac=0.5) \n",
    "data_valid = data_valid_test.drop(data_test.index) \n",
    "data_train = data.drop(data_valid_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning Models\n",
    "**STEPS:**\n",
    "* Prepare Stop Words for the medical corpus\n",
    "* Extract TFIDF vectors for the discharge summaries\n",
    "* Train tree based classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare \"stop words\" for medical corpus\n",
    "**MEDICAL_STOP_WORDS** = **ENGLISH_STOPWORDS** + \n",
    "                         **MOST FREQUENT WORDS IN THE CORPUS** + \n",
    "                         **LEAST FREQUENT WORDS IN THE CORPUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST FREQUENT WORDS\n",
      "--------------------\n",
      "['mg', 'tablet', 'po', 'patient', 'sig', 'blood', 'daily', 'hospital', 'discharge', 'day', 'history', 'left', 'pm', 'right', 'pain', 'admission', 'pt', 'date', 'ct', 'normal']\n",
      "\n",
      "\n",
      "LEAST FREQUENT WORDS\n",
      "--------------------\n",
      "['occais', 'occaional', 'octeotide', 'october', 'oldhealed', 'octogenerian', 'ohd', 'diagnosiscongestive', 'ogts', 'diagnosislast', 'ogng', 'ogett', 'diagnosispericardial', 'ofsteroids', 'ofsmoking', 'ofpneumonia', 'diagnositc', 'oflow', 'ofliothyronine', 'ofindinavir']\n"
     ]
    }
   ],
   "source": [
    "# English stopwords from Reuters\n",
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards']\n",
    "stopwords += ['again', 'against', 'all', 'almost', 'alone', 'along']\n",
    "stopwords += ['already', 'also', 'although', 'always', 'am', 'among']\n",
    "stopwords += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another']\n",
    "stopwords += ['any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\n",
    "stopwords += ['are', 'around', 'as', 'at', 'back', 'be', 'became']\n",
    "stopwords += ['because', 'become', 'becomes', 'becoming', 'been']\n",
    "stopwords += ['before', 'beforehand', 'behind', 'being', 'below']\n",
    "stopwords += ['beside', 'besides', 'between', 'beyond', 'bill', 'both']\n",
    "stopwords += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant']\n",
    "stopwords += ['co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\n",
    "stopwords += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due']\n",
    "stopwords += ['during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\n",
    "stopwords += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever']\n",
    "stopwords += ['every', 'everyone', 'everything', 'everywhere', 'except']\n",
    "stopwords += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first']\n",
    "stopwords += ['five', 'for', 'former', 'formerly', 'forty', 'found']\n",
    "stopwords += ['four', 'from', 'front', 'full', 'further', 'get', 'give']\n",
    "stopwords += ['go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\n",
    "stopwords += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers']\n",
    "stopwords += ['herself', 'him', 'himself', 'his', 'how', 'however']\n",
    "stopwords += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed']\n",
    "stopwords += ['interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\n",
    "stopwords += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made']\n",
    "stopwords += ['many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\n",
    "stopwords += ['more', 'moreover', 'most', 'mostly', 'move', 'much']\n",
    "stopwords += ['must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\n",
    "stopwords += ['nevertheless', 'next', 'nine', 'no', 'nobody', 'none']\n",
    "stopwords += ['noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\n",
    "stopwords += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or']\n",
    "stopwords += ['other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\n",
    "stopwords += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please']\n",
    "stopwords += ['put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\n",
    "stopwords += ['seeming', 'seems', 'serious', 'several', 'she', 'should']\n",
    "stopwords += ['show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\n",
    "stopwords += ['some', 'somehow', 'someone', 'something', 'sometime']\n",
    "stopwords += ['sometimes', 'somewhere', 'still', 'such', 'system', 'take']\n",
    "stopwords += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves']\n",
    "stopwords += ['then', 'thence', 'there', 'thereafter', 'thereby']\n",
    "stopwords += ['therefore', 'therein', 'thereupon', 'these', 'they']\n",
    "stopwords += ['thick', 'thin', 'third', 'this', 'those', 'though', 'three']\n",
    "stopwords += ['three', 'through', 'throughout', 'thru', 'thus', 'to']\n",
    "stopwords += ['together', 'too', 'toward', 'towards', 'twelve']\n",
    "stopwords += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon']\n",
    "stopwords += ['us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\n",
    "stopwords += ['whatever', 'when', 'whence', 'whenever', 'where']\n",
    "stopwords += ['whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\n",
    "stopwords += ['wherever', 'whether', 'which', 'while', 'whither', 'who']\n",
    "stopwords += ['whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\n",
    "stopwords += ['within', 'without', 'would', 'yet', 'you', 'your']\n",
    "stopwords += ['yours', 'yourself', 'yourselves']\n",
    "\n",
    "# Prepare 100_most_frequent and least_frequent non-stopwords tokens in the train data \n",
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "bow_matrix = bow_vectorizer.fit_transform(data_train['TEXT_CLEAN'])\n",
    "\n",
    "# Make a dataframe\n",
    "term_freq = bow_matrix.sum(axis=0)\n",
    "bow_df = pd.DataFrame(\n",
    "    term_freq, columns=bow_vectorizer.get_feature_names()).transpose()\n",
    "bow_df = bow_df.reset_index(drop=False)\n",
    "bow_df.columns=['term', 'frequency']\n",
    "bow_df.sort_values(by='frequency', ascending=False, inplace=True)\n",
    "\n",
    "# Find the most_frequent and least_frequent words\n",
    "hundred_most_freq_words = bow_df['term'].tolist()[:100]\n",
    "hundred_least_freq_words = bow_df['term'].tolist()[-100:]\n",
    "\n",
    "print(\"MOST FREQUENT WORDS\")\n",
    "print('-'*20)\n",
    "print(hundred_most_freq_words[:20])\n",
    "print('\\n')\n",
    "print(\"LEAST FREQUENT WORDS\")\n",
    "print('-'*20)\n",
    "print(hundred_least_freq_words[:20])\n",
    "\n",
    "# Join all three lists to make a medical_corpus_stopwords\n",
    "med_corpus_stopwords = set(stopwords + hundred_least_freq_words + hundred_most_freq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_uni = TfidfVectorizer(token_pattern=r'\\b\\w+\\b', stop_words=med_corpus_stopwords, min_df=2, max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_matrix = tfidf_uni.fit_transform(data_train ['TEXT_CLEAN'])\n",
    "valid_data_matrix = tfidf_uni.transform(data_valid ['TEXT_CLEAN'])\n",
    "test_data_matrix = tfidf_uni.transform(data_test ['TEXT_CLEAN'])                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['Label']\n",
    "y_valid = data_valid['Label']\n",
    "y_test = data_test['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Model_01; Random Forest Base Model with unigrams tfidf\n",
    "\n",
    "# Instantiate and fit a model to the training data\n",
    "model_01 = RandomForestClassifier()\n",
    "model_01.fit(train_data_matrix, y_train)\n",
    "\n",
    "# Save and load data\n",
    "filename = 'rf_base_model_MF.sav'\n",
    "pickle.dump(model_01, open(filename, 'wb'))\n",
    "model_01 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Make predictions\n",
    "trn_preds_01 = model_01.predict(train_data_matrix)\n",
    "valid_preds_01 =model_01.predict(valid_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF BASE MODEL PPERFORMANCE ON TRAINING DATA\n",
      "-------------------------------------------------------\n",
      "Accuracy is 0.98\n",
      "Precision is 0.99\n",
      "Recall is 0.98\n",
      "AUC is 0.98\n",
      "\n",
      "\n",
      "RF BASE MODEL PPERFORMANCE ON VALIDATION DATA\n",
      "-------------------------------------------------------\n",
      "Accuracy is 0.59\n",
      "Precision is 0.62\n",
      "Recall is 0.49\n",
      "AUC is 0.59\n"
     ]
    }
   ],
   "source": [
    "print('RF BASE MODEL PPERFORMANCE ON TRAINING DATA')\n",
    "print('-'*55)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, trn_preds_01)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_train, trn_preds_01)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_train, trn_preds_01)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train, trn_preds_01)))\n",
    "print('\\n')\n",
    "print('RF BASE MODEL PPERFORMANCE ON VALIDATION DATA')\n",
    "print('-'*55)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_valid, valid_preds_01)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_valid, valid_preds_01)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_valid, valid_preds_01)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_valid, valid_preds_01)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper Parameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap='True', class_weight=None, criterion='gini',\n",
       "            max_depth=178, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=4, min_samples_split=25,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the random grid of hyperparameters\n",
    "random_grid = {'n_estimators': [int(x) for x in np.linspace(start=100, stop=1000, num=10)],\n",
    "               'max_features': ['sqrt', 'log2'],\n",
    "               'max_depth': [int(x) for x in np.linspace(50, 400, num=20)],\n",
    "               'min_samples_split': [2, 5, 10, 15, 20, 25, 30],\n",
    "               'min_samples_leaf': [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "               'bootstrap' : ['True', 'False']}\n",
    "\n",
    "\n",
    "# Instantiate a random search CV model\n",
    "model_02 = RandomizedSearchCV(estimator=model_01, param_distributions=random_grid,\n",
    "                                 n_iter=100, cv=3, verbose=True, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit a model to the training data\n",
    "model_02.fit(train_data_matrix, y_train)\n",
    "\n",
    "# Obtain the hyperparameters for the best model\n",
    "best_random_02 = model_02.best_estimator_\n",
    "best_random_02\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run model with the best parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_02_best = RandomForestClassifier(bootstrap='False', class_weight=None, criterion='gini',\n",
    "                                       max_depth=68, max_features='log2', max_leaf_nodes=None,\n",
    "                                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                       min_samples_leaf=8, min_samples_split=5,\n",
    "                                       min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
    "                                       oob_score=False, random_state=None, verbose=0,\n",
    "                                       warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap='False', class_weight=None, criterion='gini',\n",
       "            max_depth=68, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=8, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_02_best.fit(train_data_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the model\n",
    "filename = 'rf_best_model_MF.sav'\n",
    "pickle.dump(model_02_best, open(filename, 'wb'))\n",
    "model_02_best = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Predict the labels of the train and validation data\n",
    "trn_preds_02 = model_02_best.predict(train_data_matrix)\n",
    "valid_preds_02 = model_02_best.predict(valid_data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF BEST RANDOM MODEL PPERFORMANCE ON TRAINING DATA\n",
      "-----------------------------------------------------------------\n",
      "Accuracy is 0.91\n",
      "Precision is 0.91\n",
      "Recall is 0.91\n",
      "AUC is 0.91\n",
      "\n",
      "\n",
      "RF BEST RANDOM MODEL PPERFORMANCE ON VALIDATION DATA\n",
      "-----------------------------------------------------------------\n",
      "Accuracy is 0.64\n",
      "Precision is 0.63\n",
      "Recall is 0.67\n",
      "AUC is 0.64\n"
     ]
    }
   ],
   "source": [
    "print('RF BEST RANDOM MODEL PPERFORMANCE ON TRAINING DATA')\n",
    "print('-'*65)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, trn_preds_02)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_train, trn_preds_02)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_train, trn_preds_02)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train, trn_preds_02)))\n",
    "print('\\n')\n",
    "print('RF BEST RANDOM MODEL PPERFORMANCE ON VALIDATION DATA')\n",
    "print('-'*65)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_valid, valid_preds_02)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_valid, valid_preds_02)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_valid, valid_preds_02)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_valid, valid_preds_02)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting Machine Base Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a classifier\n",
    "model_03 = GradientBoostingClassifier()\n",
    "\n",
    "# Fit a model\n",
    "model_03.fit(train_data_matrix, y_train)\n",
    "\n",
    "# Save and load the model\n",
    "filename = 'gbm_base_model_MF.sav'\n",
    "pickle.dump(model_03, open(filename, 'wb'))\n",
    "model_03 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "\n",
    "# Predict the labels of the train and valid data\n",
    "trn_preds_03 = model_03.predict(train_data_matrix)\n",
    "valid_preds_03 = model_03.predict(valid_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting Machine Base Model Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM BASE MODEL PPERFORMANCE ON TRAINING DATA\n",
      "-----------------------------------------------------------------\n",
      "Accuracy is 0.88\n",
      "Precision is 0.88\n",
      "Recall is 0.88\n",
      "AUC is 0.88\n",
      "\n",
      "\n",
      "GBM BASE MODEL PPERFORMANCE ON VALIDATION DATA\n",
      "-----------------------------------------------------------------\n",
      "Accuracy is 0.61\n",
      "Precision is 0.62\n",
      "Recall is 0.59\n",
      "AUC is 0.61\n"
     ]
    }
   ],
   "source": [
    "print('GBM BASE MODEL PPERFORMANCE ON TRAINING DATA')\n",
    "print('-'*65)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, trn_preds_03)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_train, trn_preds_03)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_train, trn_preds_03)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train, trn_preds_03)))\n",
    "print('\\n')\n",
    "print('GBM BASE MODEL PPERFORMANCE ON VALIDATION DATA')\n",
    "print('-'*65)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_valid, valid_preds_03)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_valid, valid_preds_03)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_valid, valid_preds_03)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_valid, valid_preds_03)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Search Hyperparameter Tuning for Gradient Boosting Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "params_GB_RS = {\"max_depth\": np.linspace(1, 50, 5, endpoint=True),\n",
    "                \"max_features\": ['auto', 'sqrt', 'log2'],\n",
    "                \"min_samples_split\": np.linspace(.1, 1, 10, endpoint=True),\n",
    "                \"min_samples_leaf\": [.1, .2,.3, .4, .5],\n",
    "                \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 1, 2]}\n",
    "\n",
    "\n",
    "model_04 = RandomizedSearchCV(model_03, param_distributions=params_GB_RS,\n",
    "                                 n_iter=100, cv=3, verbose=True, random_state=42, n_jobs=-1)\n",
    "\n",
    "model_04.fit(train_data_matrix, y_train)\n",
    "\n",
    "best_GBM = model_04.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_06 = GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                      max_depth=17.333333333333336,\n",
    "                                      max_features='log2',\n",
    "                                      min_samples_leaf=0.24,\n",
    "                                      min_samples_split=0.6,\n",
    "                                      n_estimators=1000)\n",
    "\n",
    "\n",
    "model_06.fit(train_data_matrix, y_train)\n",
    "\n",
    "filename = 'gbm_best_model.sav'\n",
    "pickle.dump(model_06, open(filename, 'wb'))\n",
    "model_06 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "trn_preds_06 = model_06.predict(train_data_matrix)\n",
    "valid_preds_06 = model_06.predict(valid_data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Metrics for the best hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM BEST MODEL PPERFORMANCE ON TRAINING DATA\n",
      "-----------------------------------------------------------------\n",
      "Accuracy is 0.62\n",
      "Precision is 0.62\n",
      "Recall is 0.65\n",
      "AUC is 0.62\n",
      "\n",
      "\n",
      "GBM BEST MODEL PPERFORMANCE ON VALIDATION DATA\n",
      "-----------------------------------------------------------------\n",
      "Accuracy is 0.57\n",
      "Precision is 0.56\n",
      "Recall is 0.61\n",
      "AUC is 0.57\n"
     ]
    }
   ],
   "source": [
    "print('GBM BEST MODEL PPERFORMANCE ON TRAINING DATA')\n",
    "print('-'*65)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_train, trn_preds_06)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_train, trn_preds_06)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_train, trn_preds_06)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_train, trn_preds_06)))\n",
    "print('\\n')\n",
    "print('GBM BEST MODEL PPERFORMANCE ON VALIDATION DATA')\n",
    "print('-'*65)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_valid, valid_preds_06)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_valid, valid_preds_06)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_valid, valid_preds_06)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_valid, valid_preds_06)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'gbm_best_model.sav'\n",
    "pickle.dump(model_06, open(filename, 'wb'))\n",
    "\n",
    "model_06 = pickle.load(open(filename, 'rb'))\n",
    "valid_preds_06 = model_06.predict(valid_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = pd.DataFrame(valid_data_matrix.toarray(), columns=tfidf_uni.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perm = PermutationImportance(model_06, random_state=1).fit(valid_data, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0075\n",
       "                \n",
       "                    &plusmn; 0.0027\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                extremities\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0072\n",
       "                \n",
       "                    &plusmn; 0.0051\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                multiple\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0069\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                head\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0063\n",
       "                \n",
       "                    &plusmn; 0.0064\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                results\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0057\n",
       "                \n",
       "                    &plusmn; 0.0035\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                nontender\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0057\n",
       "                \n",
       "                    &plusmn; 0.0035\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                major\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0051\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                invasive\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0051\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                injection\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0051\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                good\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0051\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                currently\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0051\n",
       "                \n",
       "                    &plusmn; 0.0055\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                brief\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0048\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                vancomycin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0048\n",
       "                \n",
       "                    &plusmn; 0.0044\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                complaint\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0048\n",
       "                \n",
       "                    &plusmn; 0.0029\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sulfate\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "                    &plusmn; 0.0038\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ed\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mental\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                surgical\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "                    &plusmn; 0.0050\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                diabetes\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "                    &plusmn; 0.0029\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                recently\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                abdomen\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.67%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 4980 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(perm, feature_names = valid_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({'classifier': ['RF_base_uni', 'RF_base_uni', 'RF_tuned_uni', 'RF_tuned_uni', 'GBM_base_uni', 'GBM_base_uni', 'GBM_tuned_uni', 'GBM_tuned_uni'],\n",
    "                           'data_set': ['train', 'valid']*4,\n",
    "\n",
    "                           'AUC': [0.98, 0.59, 0.91, 0.64, 0.88, 0.61, 0.62, 0.57]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x=\"classifier\", hue=\"data_set\", y=\"AUC\", data=df_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
